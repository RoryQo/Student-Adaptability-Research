{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c7fd9d9",
   "metadata": {},
   "source": [
    "## Mini-Project  \n",
    "### Part 1: Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18770c11",
   "metadata": {},
   "source": [
    "Study studentsâ€™ adaptability to online learning.\n",
    "+ Create frequency tables\n",
    "+ Encode all categorical variables\n",
    "    + Scale variables\n",
    "+ Deal with missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db501144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(r\"C:\\Users\\roryq\\Downloads\\online_adapt.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e44858c",
   "metadata": {},
   "source": [
    "There is no missing value in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc57fa4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender                 0\n",
       "Age                    0\n",
       "Education Level        0\n",
       "Institution Type       0\n",
       "IT Student             0\n",
       "Location               0\n",
       "Load-shedding          0\n",
       "Financial Condition    0\n",
       "Internet Type          0\n",
       "Network Type           0\n",
       "Class Duration         0\n",
       "Self Lms               0\n",
       "Device                 0\n",
       "Adaptivity Level       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e38175d",
   "metadata": {},
   "source": [
    "### Understand the data\n",
    "#### Display the frequency table for the response variable, `Adaptivity Level`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "af53a6bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_eee9a\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_eee9a_level0_col0\" class=\"col_heading level0 col0\" >High</th>\n",
       "      <th id=\"T_eee9a_level0_col1\" class=\"col_heading level0 col1\" >Low</th>\n",
       "      <th id=\"T_eee9a_level0_col2\" class=\"col_heading level0 col2\" >Moderate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_eee9a_row0_col0\" class=\"data row0 col0\" >100</td>\n",
       "      <td id=\"T_eee9a_row0_col1\" class=\"data row0 col1\" >480</td>\n",
       "      <td id=\"T_eee9a_row0_col2\" class=\"data row0 col2\" >625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1ac60c99c10>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create function that counts the number of argument (x)\n",
    "# Group data frame by adaptability level, then apply the count function we created\n",
    "# Create new data frame by extracting single column of df\n",
    "    # Transpose it to look prettier\n",
    "    # Hide index to avoid the column name and only view adaptability level\n",
    "    \n",
    "def ct(x):\n",
    "    return x.count()\n",
    "t= pd.DataFrame(data.groupby('Adaptivity Level').apply(ct))\n",
    "pd.DataFrame(t[\"Age\"]).T.style.hide(axis='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87621f50",
   "metadata": {},
   "source": [
    "#### Display the frequency table for `Education Level`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f9dba2cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_4d33e\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_4d33e_level0_col0\" class=\"col_heading level0 col0\" >College</th>\n",
       "      <th id=\"T_4d33e_level0_col1\" class=\"col_heading level0 col1\" >School</th>\n",
       "      <th id=\"T_4d33e_level0_col2\" class=\"col_heading level0 col2\" >University</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_4d33e_row0_col0\" class=\"data row0 col0\" >219</td>\n",
       "      <td id=\"T_4d33e_row0_col1\" class=\"data row0 col1\" >530</td>\n",
       "      <td id=\"T_4d33e_row0_col2\" class=\"data row0 col2\" >456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1ac615a8610>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create function that counts the number of argument (x)\n",
    "# Group data frame by adaptability level, then apply the count function we created\n",
    "# Create new data frame by extracting single column of df\n",
    "    # Transpose it to look prettier\n",
    "    # Hide index to avoid the column name and only view adaptability level\n",
    "    \n",
    "def ct(x):\n",
    "    return x.count()\n",
    "t= pd.DataFrame(data.groupby('Education Level').apply(ct))\n",
    "pd.DataFrame(t[\"Age\"]).T.style.hide(axis='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4c4ff9",
   "metadata": {},
   "source": [
    "#### Write a function to show the unique values of each variable in the dataset.  Then apply this function on the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5c20613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Boy' 'Girl']\n",
      "['21-25' '16-20' '11-15' '26-30' '6-10' '1-5']\n",
      "['University' 'College' 'School']\n",
      "['Non Government' 'Government']\n",
      "['No' 'Yes']\n",
      "['Yes' 'No']\n",
      "['Low' 'High']\n",
      "['Mid' 'Poor' 'Rich']\n",
      "['Wifi' 'Mobile Data']\n",
      "['4G' '3G' '2G']\n",
      "['3-6' '1-3' '0']\n",
      "['No' 'Yes']\n",
      "['Tab' 'Mobile' 'Computer']\n",
      "['Moderate' 'Low' 'High']\n"
     ]
    }
   ],
   "source": [
    "# Write a function to show the unique values of each variable \n",
    "# in the dataset.  \n",
    "# Then apply this function on the dataset.\n",
    "\n",
    "df= data\n",
    "for col in df:\n",
    "    print(df[col].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674dcb98",
   "metadata": {},
   "source": [
    "### Encode Categorical Variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ae0d45",
   "metadata": {},
   "source": [
    "#### Encode `Age` to integers, 1, 2, 3, 4, 5, 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "621fe1c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['21-25', '16-20', '11-15', '26-30', '6-10', '1-5'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find unique age values to encode\n",
    "\n",
    "data[\"Age\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2926cda1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       5\n",
       "1       5\n",
       "2       4\n",
       "3       3\n",
       "4       4\n",
       "       ..\n",
       "1200    4\n",
       "1201    4\n",
       "1202    3\n",
       "1203    4\n",
       "1204    3\n",
       "Name: Age, Length: 1205, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use scale to assign these age values to an integer\n",
    "# 1 to the youngest group\n",
    "# View data with new encoded scale\n",
    "\n",
    "scale = {'1-5': 1,\n",
    "         '6-10':2,\n",
    "         '11-15':3,\n",
    "         '16-20':4,\n",
    "         '21-25':5,\n",
    "         '26-30':6,}\n",
    "data['Age'].replace(scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ba4717",
   "metadata": {},
   "source": [
    "#### Encode `Network Type` to integers, 2, 3, 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "042b25bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['4G', '3G', '2G'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find unique network values to encode\n",
    "data[\"Network Type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "067783f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use scale to assign these Network type values to an integer\n",
    "# 1 to the lowest G\n",
    "\n",
    "\n",
    "scale1 = {'2G': 2,\n",
    "         '3G':3,\n",
    "         '4G':4,}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3024c8c8",
   "metadata": {},
   "source": [
    "#### Encode `Class Duration` to integers, 0, 1, 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30040a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['3-6', '1-3', '0'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find unique class durations to encode\n",
    "data[\"Class Duration\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a3b2c623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use scale to assign these class durations type values to an integer\n",
    "# 1 to the shortest duration\n",
    "\n",
    "\n",
    "\n",
    "scale2 = {'0': 0,\n",
    "         '1-3':1,\n",
    "         '3-6':2,}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7750d907",
   "metadata": {},
   "source": [
    "#### Replace `Age`, `Network Type`, `Class Duration` by their corresponding encoded numeric variables you defined in 2.2 to 2.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7b56cfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the columns of the data frame as the new encoded columns for each variable\n",
    "\n",
    "\n",
    "data['Class Duration']=data['Class Duration'].replace(scale2)\n",
    "data['Network Type'] = data['Network Type'].replace(scale1)\n",
    "data.Age= data['Age'].replace(scale)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c92abf",
   "metadata": {},
   "source": [
    "#### One-hot encode the rest of the variables except for the response variable, `Adaptivity Level`.\n",
    "\n",
    "* Name the data frame `data1`. Note that `data1` should have all the encoded features (without the response variable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ab948554",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelBinarizer \n",
    "\n",
    "\n",
    "# Create dummy variables for other categorical variables\n",
    "# View data saved as data1\n",
    "\n",
    "data1 = pd.get_dummies(data, columns = ['Education Level', \n",
    "                                               'Gender', 'Location', 'Institution Type', \n",
    "                                               'IT Student', 'Load-shedding', 'Financial Condition'\n",
    "                                               , 'Internet Type', 'Device', 'Self Lms' ], dtype=int)\n",
    "data1= data1.drop('Adaptivity Level', axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514620e1",
   "metadata": {},
   "source": [
    "### Scale Numeric Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348b0f9a",
   "metadata": {},
   "source": [
    "#### Use `MinMaxScaler` to rescale all variables.\n",
    "The scaled dataset will be called `data2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4ddcc9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Create for loop to apply the MinMaxScaler to all columns in df\n",
    "\n",
    "datac= data1.copy()\n",
    "for col in datac:\n",
    "    scaler = MinMaxScaler()\n",
    "    datac[[col]]= scaler.fit_transform(datac[[col]])\n",
    "\n",
    "# Save as data2     \n",
    "data2=datac"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4690d5",
   "metadata": {},
   "source": [
    "####  Verify that the min is 0 and and the max is 1 for each column. Requirement: Use a `for` loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f98a7527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Min and Max are Correct\n"
     ]
    }
   ],
   "source": [
    "# Check to see if min is 0 and max is 1 for each column in the data frame (True)\n",
    "# If not print each column and its min and max\n",
    "\n",
    "for col in data2:\n",
    "    if round(data2[col].min())==0 and  round(data2[col].max())== 1:\n",
    "        found=True\n",
    "if found:\n",
    "    print(\"All Min and Max are Correct\")\n",
    "else:\n",
    "    for col in data2:\n",
    "     print( col, 'Min is', round(data2[col].min()),'Max is', round(data2[col].max()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da0333a",
   "metadata": {},
   "source": [
    "#### Standardizing all features in `data1`. Name the new data frame `data3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1ad5ee10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Create for loop to apply the StandardScaler to all columns in df\n",
    "\n",
    "data3 = data2.copy()\n",
    "\n",
    "\n",
    "for col in data3:\n",
    "    scaler2 = StandardScaler()\n",
    "    data3[[col]]= scaler2.fit_transform(data3[[col]])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01fbca9",
   "metadata": {},
   "source": [
    "####  Verify the mean is 0 and the standard deviation is 1 for each column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "421c3991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Mean and Standard deviation are Correct\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check to see if mean is 0 and std is 1 for each column in the data frame (True)\n",
    "# If not print each column and its mean and std\n",
    "\n",
    "for col in data3:\n",
    "    if round(data3[col].mean())==0 and  round(data3[col].std())== 1:\n",
    "        found=True\n",
    "if found:\n",
    "    print(\"All Mean and Standard deviation are Correct\")\n",
    "else:\n",
    "    for col in data2:\n",
    "     print( col, 'Mean is', round(data3[col].mean()),'Std is', round(data3[col].std()))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9471cd1",
   "metadata": {},
   "source": [
    "####  Use a robust scaler to rescale all the features in `data1`. Name the new data frame `data4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8c21a059",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Create for loop to apply the StandardScaler to all columns in df\n",
    "\n",
    "data4 = data1.copy()\n",
    "\n",
    "\n",
    "for col in data4:\n",
    "    scaler3 = RobustScaler()\n",
    "    data4[[col]]= scaler3.fit_transform(data4[[col]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d2a0b1",
   "metadata": {},
   "source": [
    "#### Normalize all features in `data1`. Name the new data frame `data5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fd89001f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "data5 = data1.copy()\n",
    "\n",
    "for col in data5:\n",
    "    scaler4 = Normalizer()\n",
    "    data5[[col]]= scaler4.fit_transform(data5[[col]])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0ff35d",
   "metadata": {},
   "source": [
    "#### Calculate and save the norm of each observation. Then, calculate the mean and the variance of those norms in order to verify that the norms are all equal to 1.\n",
    "Hints:\n",
    "* You need to convert `data5` to a data frame using `pd.DataFrame`.\n",
    "* You may use the `apply` function to calculate the norms.\n",
    "* By default, `apply` loops across columns of a data frame. So, to use it correctly in this data frame, you need to transpose `data5` using the dot function `.T` and save the transposed data frame as `data6`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a0fe3771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Mean and Standard deviation are Correct\n"
     ]
    }
   ],
   "source": [
    "# Transpose data set to loop across with .apply()\n",
    "# Calculate norm \n",
    "# Use for loop to check mean and std of each column is 1,0, print correct if so\n",
    "\n",
    "\n",
    "data6= data5.T\n",
    "data6.apply(np.linalg.norm)\n",
    "\n",
    "for col in data6:\n",
    "    if round(data6[col].mean())==0 and  round(data6[col].std())== 1:\n",
    "        found=True\n",
    "if found:\n",
    "    print(\"All Mean and Standard deviation are Correct\")\n",
    "else:\n",
    "    for col in data6:\n",
    "     print( col, 'Mean is', round(data6[col].mean()),'Std is', round(data6[col].std()))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9d0b6d",
   "metadata": {},
   "source": [
    "### Imputing missing values\n",
    "There is no missing value in the dataset. To practice imputing missing values, we will manually change a value to `np.nan`. To make it very obvious, we will do it to the first observation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "82c20a83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Boy'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Gender'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2182faf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create missing value\n",
    "\n",
    "value_true = data.iloc[0,0]\n",
    "data.iloc[0,0] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0463e39d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View to check it is now missing\n",
    "\n",
    "data['Gender'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7233b7",
   "metadata": {},
   "source": [
    "#### Use the most frequent value to impute this missing value.\n",
    "* Verify that it uses the most frequent value, `School`.\n",
    "* Compare it with the true value. Are they the same?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "bf98c9cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Boy'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Use most frequent value strategy to fill missing value in SimpleImputer\n",
    "# Use imputer to transform the selected data\n",
    "# View Imputation\n",
    "\n",
    "imputer= SimpleImputer(missing_values= np.nan, strategy= 'most_frequent')\n",
    "data.Gender=imputer.fit_transform(data[['Gender']])\n",
    "data['Gender'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63400e4c",
   "metadata": {},
   "source": [
    "+ The value of the imputer based on most frequent is Boy, which is the same as in the original data frame, before replacing it with nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6fad667a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Boy\n",
       "Name: Gender, dtype: object"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check mode for the column and make sure it matches imuted data\n",
    "data['Gender'].mode()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
